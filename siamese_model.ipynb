{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_directory = 'sketch_small'\n",
    "TARGET_SIZE = (64, 64)\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(directory):\n",
    "    #directory is the path of the dataset (main folder)\n",
    "    #folders are classes in dataset\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    \n",
    "    folders = os.listdir(directory)\n",
    "    for folder_name in folders:\n",
    "        folder_path = os.path.join(directory, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            images = os.listdir(folder_path)\n",
    "            \n",
    "            folder_length = len(images)\n",
    "            for i in range(folder_length):\n",
    "                for j in range(folder_length):\n",
    "                    if i != j:\n",
    "                        image_path = os.path.join(folder_path, images[i])\n",
    "                        pairs.append([image_path, os.path.join(folder_path, images[j])])\n",
    "                        labels.append(1)#positive pairs\n",
    "                        \n",
    "                        dif_folder = random.choice([x for x in folders if x != folder_name])\n",
    "                        dif_folder_path = os.path.join(directory, dif_folder)\n",
    "                        dif_image_path = os.path.join(dif_folder_path, random.choice(os.listdir(dif_folder_path)))\n",
    "\n",
    "                        pairs.append([image_path, dif_image_path])\n",
    "                        labels.append(0)#negative pairs\n",
    "                        \n",
    "    return np.array(pairs), np.array(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_model(input_shape, embeddingDim = 48):\n",
    "  inputs = Input(input_shape)\n",
    "  x = Conv2D(128, (2, 2), padding = \"same\", activation = \"relu\")(inputs)\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "  x = Dropout(0.4)(x)\n",
    "\n",
    "  x = Conv2D(128, (2, 2), padding = \"same\", activation = \"relu\")(inputs)\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "  x = Dropout(0.4)(x)\n",
    "\n",
    "\n",
    "  pooling = GlobalAveragePooling2D()(x)\n",
    "  outputs = Dense(embeddingDim)(pooling)\n",
    "  model = Model(inputs, outputs)\n",
    "\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(pairs, target_size):\n",
    "    images = []\n",
    "     \n",
    "    for pair in pairs:\n",
    "        img1 = load_img(pair[0], target_size=target_size, color_mode='grayscale')\n",
    "        img2 = load_img(pair[1], target_size=target_size, color_mode='grayscale')\n",
    "\n",
    "        images.append((img1, img2))\n",
    "        \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastiveLoss(y, y_preds, margin=1):\n",
    "    y = tf.cast(y, y_preds.dtype)\n",
    "    y_preds_squared = K.square(y_preds)\n",
    "    margin_squared = K.square(K.maximum(margin - y_preds, 0))\n",
    "    loss = K.mean(y * y_preds_squared + (1 - y) * margin_squared)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(images, labels):\n",
    "  imagePairs = []\n",
    "  labelPairs = []\n",
    "\n",
    "  #Getting the indices of each class\n",
    "  numclasses = len(np.unique(labels))\n",
    "  idx = [np.where(labels ==i)[0] for i in range(numclasses)]\n",
    "\n",
    "\n",
    "  for ind in range(len(images)):\n",
    "    #Getting current image with index\n",
    "    currImage = images[ind]\n",
    "    #getting the label of the image from labels.\n",
    "    label = labels[ind]\n",
    "\n",
    "\n",
    "    #Randomly choosing another labels from the same class\n",
    "    indB = np.random.choice(idx[label])\n",
    "    #corresponding image for this randomly selected label\n",
    "    indImage = images[indB]\n",
    "\n",
    "\n",
    "    imagePairs.append([currImage, indImage])\n",
    "\n",
    "\n",
    "    labelPairs.append([1])\n",
    "\n",
    "\n",
    "    #Getting a label where label is different than the current image\n",
    "    diss_idx = np.where(labels != label)[0]\n",
    "\n",
    "\n",
    "    #finding an image for this label\n",
    "    diss_image = images[np.random.choice(diss_idx)]\n",
    "\n",
    "\n",
    "    imagePairs.append([currImage, diss_image])\n",
    "    labelPairs.append([0])\n",
    "\n",
    "\n",
    "  return (np.array(imagePairs), np.array(labelPairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vecs):\n",
    "  (imgA, imgB) = vecs\n",
    "  ss = K.sum(K.square(imgA - imgB), axis = 1, keepdims=True)\n",
    "  return K.sqrt(K.maximum(ss, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis = -1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "\n",
    "(training_pairs, training_labels) = create_pairs(x_train, y_train)\n",
    "(test_pairs, test_labels) = create_pairs(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vlns\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:174: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_shape = (28, 28, 1)\n",
    "# specify the batch size and number of epochs\n",
    "batch_size = 64\n",
    "epochs = 70\n",
    "\n",
    "imageA = Input(shape = image_shape)\n",
    "imageB = Input(shape = image_shape)\n",
    "\n",
    "\n",
    "model_build = siamese_model(image_shape)\n",
    "modelA = model_build(imageA)\n",
    "modelB = model_build(imageB)\n",
    "\n",
    "\n",
    "distance = Lambda(euclidean_distance)([modelA, modelB])\n",
    "model = Model(inputs=[imageA, imageB], outputs=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = contrastiveLoss, optimizer=\"adam\")\n",
    "history = model.fit(\n",
    "    [training_pairs[:, 0], training_pairs[:, 1]], training_labels[:],\n",
    "    validation_data=([test_pairs[:, 0], test_pairs[:, 1]], test_labels[:]),\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
